---
title: "HW3"
output: github_document
---

#Load Libraries and Set-Up
```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(viridis)
knitr::opts_chunk$set(echo = TRUE)
```

#Problem 1
```{r}
#Load data from p8105 git repository

library(p8105.datasets)
data("instacart")

##Exploratory analysis to look at generally what products, aisles, and how many of each product are ordered
instacart_df =
  select(instacart, product_name, department, add_to_cart_order, reordered) %>%
  mutate(number_order = add_to_cart_order + reordered) %>%
  arrange(department) %>%
  select(-add_to_cart_order, -reordered)

instacart_df

```

##Aisles Questions
```{r}

aisles_df = 
  select(instacart, aisle_id, aisle, product_name, add_to_cart_order, reordered) %>%
  mutate(number_order = add_to_cart_order + reordered)
#Finding the number of distinct aisles 
nrow(distinct(aisles_df, aisle_id))

#Finding the aisles where the most items are ordered from
group_by(aisles_df, aisle) %>%
  summarize(n = n()) %>%
  arrange(desc(n))
  
```
There are 134 aisles in the dataset with fresh vegetables, fresh fruits, and packaged vegetables fruits aisles containing the most items ordered.

##Number of items ordered in each aisle 
```{r}
ordered_items = 
  group_by(aisles_df, aisle) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  filter(n > 10000) %>%
  mutate(number_item = (n)) %>%
  select(-n)

ordered_items

```
## Ggplot of aisles with more than 10,000 items
```{r}
ggplot(ordered_items, aes(x = number_item, y = aisle, color = aisle)) +
         geom_point()
```

## Table of top three items in Baking Ingredients, Dog Food Care, and Packaged Vegetables Fruits
```{r}
top_baking_ing = 
  filter(instacart, aisle == "baking ingredients") %>%
    pivot_wider(
      names_from = "aisle",
      values_from = "product_name"
    ) %>%
  mutate(number_ordered = add_to_cart_order + reordered) %>%
  arrange(desc(number_ordered)) %>%
  head(3)
  
top_baking_ing

top_dog_food = 
  filter(instacart, aisle == "dog food care") %>%
    pivot_wider(
      names_from = "aisle",
      values_from = "product_name"
    ) %>%
  mutate(number_ordered = add_to_cart_order + reordered) %>%
  arrange(desc(number_ordered)) %>%
  head(3)

top_dog_food

top_packaged = 
  filter(instacart, aisle == "packaged vegetables fruits") %>%
    pivot_wider(
      names_from = "aisle",
      values_from = "product_name"
    ) %>%
  mutate(number_ordered = add_to_cart_order + reordered) %>%
  arrange(desc(number_ordered)) %>%
  head(3)
  
top_packaged

top_three = 
  bind_rows(top_baking_ing, top_dog_food, top_packaged) %>%
  janitor::clean_names() %>%
  select(-everything(), number_ordered, baking_ingredients, dog_food_care, packaged_vegetables_fruits) %>%
  arrange(desc(number_ordered))

top_three
```

## Mean hour of the day Pink Lady Apples and Coffee Ice Cream
```{r}
mean_hour = 
  select(instacart, product_id, product_name, order_hour_of_day, order_dow) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  group_by(product_id) %>%
  mutate(week_day = recode(order_dow, 
       "0" = "Sunday",
       "1" = "Monday",
       "2" = "Tuesday",
       "3" = "Wednesday",
       "4" = "Thursday",
       "5" = "Friday",
       "6" = "Saturday")) %>%
  group_by(product_name, week_day) %>%
  mutate(mean_hour = mean(order_hour_of_day)) %>%
  select(-order_hour_of_day, -order_dow, -product_id) %>% 
  arrange(week_day) %>%
  distinct() %>%
  knitr::kable()

mean_hour

```


#Problem 2

## Cleaning BRFSS data
```{r}
library(p8105.datasets)
data("BRFSS")

brfss_data = 
  select(brfss_smart2010, everything()) %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health" | 
           response == "Excellent" | 
           response == "Very good" | 
           response == "Good" |
           response == "Fair" |
           response == "Poor") %>%
  arrange(response == "Excellent", response == "Very good", response == "Good", response == "Fair", response == "Poor")

brfss_data
  
```

## 2002:states with 7 or more locations
```{r}
first_year_data = 
  group_by(brfss_data, year) %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  count(locationabbr) %>%
  filter(n > 7) 

first_year_data
```
## 2010: states with 7 or more locations
```{r}
second_year_data = 
  group_by(brfss_data, year) %>%
  filter(year == 2010) %>%
  group_by(locationabbr) %>%
  count(locationabbr) %>%
  filter(n > 7)

second_year_data
```

##Excellent responses across statements 
```{r}
excellent_response = 
  select(brfss_data, response, year, locationabbr, data_value) %>%
  filter(response == "Excellent") %>%
  group_by(locationabbr, year) %>%
  mutate(data_location = mean(data_value)) %>%
  select(-data_value) %>%
  group_by(locationabbr) %>%
  distinct()

excellent_response
```

## Spaghetti plot of above dataset
```{r}
ggplot(excellent_response, aes(x = year, y = data_location)) + 
  geom_line(aes(group = locationabbr, color = locationabbr)) + 
  scale_color_viridis(
    name = "locationabbr",
    discrete = TRUE
  ) 
``` 

##Two panel plot showing the states in 2006 and 2010
```{r}
ny_state = 
  select(brfss_data, response, year, locationabbr, locationdesc, data_value) %>%
  filter(locationabbr == "NY") %>%
  group_by(locationdesc, response, year) %>%
  mutate(data_location = mean(data_value)) %>%
  select(-data_value) %>%
  group_by(locationabbr) %>%
  filter(xor(year == "2006", year == "2010")) %>%
  distinct()

ny_state

```

## Plot of NY in 2006 and 2010
```{r}
ggplot(ny_state, aes(x = response, y = data_location)) +
  geom_line(aes(group = locationdesc, color = locationdesc)) + 
  scale_color_viridis(
    name = "locationdesc",
    discrete = TRUE
  ) +
  facet_grid(~year)
  
```


#Problem 3
```{r}
accel_data = 
  read_csv(file = "/Users/hannahbowlin/Documents/Biostats Sem 1/Data Science 1/Data Science/Data Science 1 part a/Visualization and EDA/p8105_hw3_hmb2161/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity_amount"
  ) %>%
  group_by(day) 

accel_data
```
* In this new dataset there are 5 columns instead of over a 1400. There are now `r nrow(pull(accel_data))` rows and `r ncol(pull(accel_data))` columns. The variables are week, day_id, day, minute of the day, and amount of activity in that minute. 

NEED TO ADD WEEK DAY AND WEEKEND VARIABLES

##Total activity per day
```{r}
accel_data %>%
  group_by(week) %>%
  mutate(mean_activity = mean(activity_amount)) %>%
  group_by(day_id)
  
```


minrank!

35 different days on the plots, but you cna plot other trends as well (35 diferent lines)

convert minutes to hour, divide minute variable by 60 
